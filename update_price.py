#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
from bs4 import BeautifulSoup
import csv
import os
from datetime import datetime
import re
import json
import subprocess
from pathlib import Path

class USD2RialsUpdater:
    def __init__(self, csv_file_path="USD2Rials.csv"):
        self.csv_file_path = csv_file_path
        self.url = "https://www.tgju.org/profile/price_dollar_rl/history"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    def normalize_gregorian_date(self, date_str: str) -> str:

        if not date_str:
            return date_str
        date_str = date_str.strip()
        date_part = date_str.split()[0]
        date_part = date_part.replace('-', '/')
        parsed = None
        for fmt in ('%Y/%m/%d', '%m/%d/%Y', '%d/%m/%Y'):
            try:
                parsed = datetime.strptime(date_part, fmt)
                break
            except ValueError:
                continue
        if parsed is None:
            try:
                parts = re.split(r'[/-]', date_part)
                if len(parts) == 3:
                    if len(parts[0]) == 4 and parts[0].isdigit():
                        y, m, d = int(parts[0]), int(parts[1]), int(parts[2])
                    elif len(parts[2]) == 4 and parts[2].isdigit():
                        d, m, y = int(parts[0]), int(parts[1]), int(parts[2])
                    else:
                        raise ValueError
                    parsed = datetime(y, m, d)
            except Exception:
                parsed = None
        if parsed:
            return f"{parsed.month}/{parsed.day}/{parsed.year}"
        return date_str

    def fetch_latest_price(self):
        """Ø§Ø² ÙˆØ¨Ø³Ø§ÛŒØª tgju Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø± Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
        try:
            response = requests.get(self.url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¬Ø¯ÙˆÙ„ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù‚ÛŒÙ…Øª
            table = soup.find('table', {'class': 'table widgets-dataTable table-hover text-center history-table'})
            if not table:
                raise ValueError("Ø¬Ø¯ÙˆÙ„ Ù‚ÛŒÙ…Øª Ø¯Ø± ÙˆØ¨Ø³Ø§ÛŒØª Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† Ø±Ø¯ÛŒÙ Ø¯Ø§Ø¯Ù‡ (Ø¨Ø¯ÙˆÙ† Ù‡Ø¯Ø±)
            first_row = table.find('tbody').find('tr')
            if not first_row:
                raise ValueError("Ù‡ÛŒÚ† Ø±Ø¯ÛŒÙ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
            
            cells = first_row.find_all('td')
            if len(cells) < 8:
                raise ValueError("ØªØ¹Ø¯Ø§Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ø± Ø¬Ø¯ÙˆÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø±Ø¯ÛŒÙ Ø§ÙˆÙ„
            # ØªØ±ØªÛŒØ¨: Ø¨ÛŒØ´ØªØ±ÛŒÙ†ØŒ Ú©Ù…ØªØ±ÛŒÙ†ØŒ Ø¨ÛŒØ´ØªØ±ÛŒÙ†ØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†ØŒ ØªØºÛŒÛŒØ±ØŒ Ø¯Ø±ØµØ¯ ØªØºÛŒÛŒØ±ØŒ ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒØŒ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ
            min_price_text = cells[1].get_text(strip=True)  # Ú©Ù…ØªØ±ÛŒÙ† Ù‚ÛŒÙ…Øª
            max_price_text = cells[2].get_text(strip=True)  # Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù‚ÛŒÙ…Øª
            raw_gregorian_date = cells[6].get_text(strip=True)  # ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ (Ø®Ø§Ù… Ø§Ø² Ø³Ø§ÛŒØª)
            gregorian_date = self.normalize_gregorian_date(raw_gregorian_date)  # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ Month/Day/Year (M/D/YYYY)
            persian_date = cells[7].get_text(strip=True)    # ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ø¯Ø¯
            min_price = int(min_price_text.replace(',', ''))
            max_price = int(max_price_text.replace(',', ''))
            avg_price = (min_price + max_price) // 2
            
            return {
                'date_pr': persian_date,
                'date_gr': gregorian_date,
                'source': 'tgju',
                'price_avg': avg_price
            }
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² ÙˆØ¨Ø³Ø§ÛŒØª: {str(e)}")
            return None
    
    def get_last_entry(self):
        """Ø¢Ø®Ø±ÛŒÙ† Ø±Ø¯ÛŒÙ Ø§Ø² ÙØ§ÛŒÙ„ CSV Ø±Ø§ Ø¨Ø§Ø²Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯"""
        try:
            if not os.path.exists(self.csv_file_path):
                return None
                
            with open(self.csv_file_path, 'r', encoding='utf-8') as file:
                csv_reader = csv.DictReader(file)
                last_row = None
                for row in csv_reader:
                    last_row = row
                return last_row
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ø±Ø¯ÛŒÙ: {str(e)}")
            return None
    
    def is_new_data(self, new_data, last_entry):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¢ÛŒØ§ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡"""
        if not last_entry:
            return True
        return new_data['date_pr'] != last_entry['date_pr']
    
    def append_to_csv(self, new_data):
        """Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„ CSV Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
        try:
            file_exists = os.path.exists(self.csv_file_path)
            
            with open(self.csv_file_path, 'a', newline='', encoding='utf-8') as file:
                fieldnames = ['date_pr', 'date_gr', 'source', 'price_avg']
                writer = csv.DictWriter(file, fieldnames=fieldnames)
                
                # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ù‡Ø¯Ø± Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³
                if not file_exists:
                    writer.writeheader()
                
                writer.writerow(new_data)
            return True
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ù†ÙˆØ´ØªÙ† Ø¯Ø± ÙØ§ÛŒÙ„ CSV: {str(e)}")
            return False
    
    def calculate_price_change(self, current_price, previous_price):
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª Ùˆ Ø¬Ù‡Øª Ø¢Ù†"""
        if not previous_price:
            return 0, ""
        
        change = current_price - int(previous_price)
        if change > 0:
            return change, "â†—ï¸"
        elif change < 0:
            return change, "â†˜ï¸"
        else:
            return 0, "â¡ï¸"

    # --- JSON helpers ---
    def to_iso_date(self, date_gr: str) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ (M/D/YYYY Ùˆ Ø§Ù†ÙˆØ§Ø¹ Ù…Ø´Ø§Ø¨Ù‡) Ø¨Ù‡ ISO 8601 (YYYY-MM-DD)."""
        if not date_gr:
            return ""
        norm = self.normalize_gregorian_date(date_gr)
        try:
            dt = datetime.strptime(norm, "%m/%d/%Y")
            return dt.strftime("%Y-%m-%d")
        except Exception:
            try:
                parts = re.split(r"[/-]", norm)
                if len(parts) == 3:
                    m, d, y = int(parts[0]), int(parts[1]), int(parts[2])
                    return f"{y:04d}-{m:02d}-{d:02d}"
            except Exception:
                pass
        return ""

    def get_csv_row_count(self) -> int:
        """ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ CSV Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ (Ø¨Ø¯ÙˆÙ† Ù‡Ø¯Ø±)"""
        try:
            if not os.path.exists(self.csv_file_path):
                return 0
            with open(self.csv_file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                next(reader, None)  # Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù‡Ø¯Ø±
                return sum(1 for _ in reader)
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø´Ù…Ø§Ø±Ø´ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ CSV: {e}")
            return 0

    def regenerate_json_files(self, pretty_path: str = "USD2Rials.json", min_path: str = "USD2Rials.min.json") -> tuple[bool, int]:
        """Ø§Ø² Ø±ÙˆÛŒ CSV Ø¯Ùˆ Ø®Ø±ÙˆØ¬ÛŒ JSON ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:
        1) ÙØ§ÛŒÙ„ ØºÛŒØ± ÙØ´Ø±Ø¯Ù‡ Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¢Ø±Ø§ÛŒÙ‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ø¨Ø¬Ú©Øªâ€ŒÙ‡Ø§
        2) ÙØ§ÛŒÙ„ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª [["YYYY-MM-DD", price], ...]
        Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯: (Ù…ÙˆÙÙ‚ÛŒØª, ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§)
        """
        try:
            full_rows = []
            min_rows = []
            row_count = 0
            with open(self.csv_file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    row_count += 1
                    date_pr = (row.get('date_pr') or '').strip()
                    date_gr = (row.get('date_gr') or '').strip()
                    source = (row.get('source') or '').strip()
                    price_str = (row.get('price_avg') or '').replace(',', '').strip()
                    try:
                        price = int(price_str)
                    except Exception:
                        continue
                    # Ø¢Ø±Ø§ÛŒÙ‡ Ú©Ø§Ù…Ù„
                    full_rows.append({
                        'date_pr': date_pr,
                        'date_gr': date_gr,
                        'source': source,
                        'price_avg': price
                    })
                    # Ø¢Ø±Ø§ÛŒÙ‡ Ù…ÛŒÙ†ÛŒÙ…Ø§Ù„
                    iso = self.to_iso_date(date_gr)
                    if iso:
                        min_rows.append([iso, price])
            # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§Ø±ÛŒØ®
            min_rows.sort(key=lambda x: x[0])
            full_rows.sort(key=lambda item: (self.to_iso_date(item.get('date_gr', '')) or '9999-99-99'))
            # Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
            with open(min_path, 'w', encoding='utf-8') as fmin:
                json.dump(min_rows, fmin, ensure_ascii=False, separators=(',', ':'))
            with open(pretty_path, 'w', encoding='utf-8') as fpretty:
                json.dump(full_rows, fpretty, ensure_ascii=False, indent=2)
            print("âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯Ù†Ø¯")
            return True, row_count
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ JSON: {e}")
            return False, 0
    
    def update_readme(self, latest_data, last_entry=None, csv_row_count=0):
        """ÙØ§ÛŒÙ„ README Ø±Ø§ Ø¨Ø§ Ø¢Ø®Ø±ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (RTL + Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ†)"""
        try:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª
            current_price = latest_data['price_avg']
            previous_price = last_entry['price_avg'] if last_entry else None
            price_change, arrow = self.calculate_price_change(current_price, int(previous_price) if previous_price else None)
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø­ØªÙˆØ§ÛŒ HTML Ø±Ø§Ø³Øªâ€ŒØ¨Ù‡â€ŒÚ†Ù¾ Ø¨Ø±Ø§ÛŒ GitHub
            readme_content = f"""
<div dir="rtl" align="right">
  <h1>Ø¢Ø±Ø´ÛŒÙˆ Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø± Ø¨Ù‡ Ø±ÛŒØ§Ù„</h1>

  <h2>ğŸ“Š Ø¢Ø®Ø±ÛŒÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª</h2>
  <p><strong>Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ:</strong> {latest_data['date_pr']} | <strong>Ù‚ÛŒÙ…Øª Ø«Ø¨Øª Ø´Ø¯Ù‡:</strong> {latest_data['price_avg']:,} Ø±ÛŒØ§Ù„ {arrow}</p>
"""
            
            if price_change != 0:
                readme_content += f"  <p><strong>ØªØºÛŒÛŒØ± Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø±ÙˆØ² Ù‚Ø¨Ù„:</strong> {price_change:+,} Ø±ÛŒØ§Ù„</p>\n"
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ CSV
            readme_content += f"  <p><strong>ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€Œ:</strong> {csv_row_count:,}</p>\n"
            
            readme_content += """
  <hr />

  <h2>ğŸ” Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù…Ø®Ø²Ù†</h2>
  <p>Ø§ÛŒÙ† Ù…Ø®Ø²Ù† Ø­Ø§ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø± Ø¢Ù…Ø±ÛŒÚ©Ø§ Ø¨Ù‡ Ø±ÛŒØ§Ù„ Ø§ÛŒØ±Ø§Ù† Ø§Ø³Øª Ú©Ù‡ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ùˆ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² Ø³Ø§ÛŒØª <strong>tgju.org</strong> Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.</p>
  <p>Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ØªØ§Ø±ÛŒØ® Û· Ù…Ù‡Ø±Ù…Ø§Ù‡ Û±Û³Û¶Û° ØªØ§ Ø¨Ù‡ Ø§Ù…Ø±ÙˆØ² Ù‡Ø³ØªÙ†Ø¯.</p>
  <p>Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø§ÛŒÙ† Ù…Ø®Ø²Ù† Ø§Ø² Ø³Ø§ÛŒØª <a href="https://d-learn.ir/usd-price/">Ù…Ø¯Ø±Ø³Ù‡ Ø¯Ù‚ÛŒÙ‚Ù‡</a> Ø¨Ø±Ø¯Ø§Ø´ØªÙ‡ Ø´Ø¯Ù‡â€ŒØ§Ø³Øª Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ø¯ÙˆØ±Ù‡â€ŒØ§ÛŒ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€Œ Ø¯Ø± Ù‡Ù…ÛŒÙ† Ù„ÛŒÙ†Ú© Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯.</p>

  <h3>ğŸ“‹ ØªÙˆØ¶ÛŒØ­Ø§Øª Ùˆ ÙØ±Ø§ÛŒÙ†Ø¯:</h3>
  <ul>
    <li><strong>Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±</strong>: Ù‡Ø± Ø±ÙˆØ² Ø³Ø§Ø¹Øª Û±Û±:Û°Û° ØµØ¨Ø­ Ø¨Ù‡ ÙˆÙ‚Øª ØªÙ‡Ø±Ø§Ù†</li>
    <li><strong>ØªØ§Ø±ÛŒØ® Ø¯ÙˆÚ¯Ø§Ù†Ù‡</strong>: Ø´Ø§Ù…Ù„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ùˆ Ù…ÛŒÙ„Ø§Ø¯ÛŒ</li>
    <li><strong>Ù‚ÛŒÙ…Øª Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†</strong>: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø² Ú©Ù…ØªØ±ÛŒÙ† Ùˆ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ù‚ÛŒÙ…Øª Ø±ÙˆØ²</li>
    <li><strong>Ù†Ù…Ø§ÛŒØ´ ØªØºÛŒÛŒØ±Ø§Øª</strong>: Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø±ÙˆØ² Ù‚Ø¨Ù„ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Ù†Ø´Ø§Ù†Ú¯Ø± Ø¯Ø± Ù…Ø®Ø²Ù†</li>
  </ul>

  <h3>ğŸ“Š Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:</h3>
  <table>
    <thead>
      <tr><th>Ø³ØªÙˆÙ†</th><th>ØªÙˆØ¶ÛŒØ­</th></tr>
    </thead>
    <tbody>
      <tr><td><code>date_pr</code></td><td>ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ (ÙØ§Ø±Ø³ÛŒ)</td></tr>
      <tr><td><code>date_gr</code></td><td>ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ (Ú¯Ø±ÛŒÚ¯ÙˆØ±ÛŒÙ†)</td></tr>
      <tr><td><code>source</code></td><td>Ù…Ù†Ø¨Ø¹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª (tgju)</td></tr>
      <tr><td><code>price_avg</code></td><td>Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‚ÛŒÙ…Øª Ø±ÙˆØ² (Ø±ÛŒØ§Ù„)</td></tr>
    </tbody>
  </table>
</div>
"""
            
            with open('README.md', 'w', encoding='utf-8') as f:
                f.write(readme_content)
            
            return True
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ README: {str(e)}")
            return False
    
    def is_first_day_of_persian_month(self, persian_date: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¢ÛŒØ§ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø±ÙˆØ² Ø§ÙˆÙ„ Ù…Ø§Ù‡ Ø§Ø³Øª ÛŒØ§ Ù†Ù‡"""
        try:
            # ÙØ±Ù…Øª ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ ØµÙˆØ±Øª "Û±Û´Û°Û³/Û°Û¶/Û°Û±" Ø§Ø³Øª
            parts = persian_date.replace('/', ' ').replace('-', ' ').split()
            if len(parts) >= 3:
                day = parts[2].strip()
                # ØªØ¨Ø¯ÛŒÙ„ Ø§Ø¹Ø¯Ø§Ø¯ ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
                persian_to_english = str.maketrans('Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹', '0123456789')
                day_english = day.translate(persian_to_english)
                return day_english == '01' or day_english == '1'
            return False
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ² Ø§ÙˆÙ„ Ù…Ø§Ù‡: {e}")
            return False
    
    def create_github_release(self, latest_data, csv_row_count: int) -> bool:
        """Ø§ÛŒØ¬Ø§Ø¯ GitHub Release Ø¨Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ùˆ JSON"""
        try:
            github_token = os.getenv('GITHUB_TOKEN')
            if not github_token:
                print("âš ï¸ GITHUB_TOKEN ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
                return False
            
            # ØªÙˆÙ„ÛŒØ¯ Ù†Ø§Ù… ØªÚ¯ Ø¨Ø§ ÙØ±Ù…Øª ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ùˆ Ø´Ù…Ø³ÛŒ
            gregorian_date = latest_data['date_gr']
            persian_date = latest_data['date_pr']
            
            # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ Ø¨Ù‡ ÙØ±Ù…Øª YYYYMMDD
            try:
                dt = datetime.strptime(gregorian_date, "%m/%d/%Y")
                gregorian_formatted = dt.strftime("%Y%m%d")
            except:
                gregorian_formatted = gregorian_date.replace('/', '')
            
            # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ Ø¨Ù‡ ÙØ±Ù…Øª YYYYMMDD
            persian_formatted = persian_date.replace('/', '').replace('-', '')
            
            tag_name = f"{gregorian_formatted}-{persian_formatted}"
            release_name = f"Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ {persian_date} - {gregorian_date}"
            
            release_body = f"""Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯Ù‡ ØªØ§ {persian_date} - {gregorian_date}
ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙ: {csv_row_count:,}"""
            
            # Ø§ÛŒØ¬Ø§Ø¯ release Ø¨Ø§ GitHub CLI
            cmd = [
                'gh', 'release', 'create', tag_name,
                '--title', release_name,
                '--notes', release_body,
                'USD2Rials.csv',
                'USD2Rials.json',
                'USD2Rials.min.json'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            
            if result.returncode == 0:
                print(f"âœ… GitHub Release {tag_name} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
                return True
            else:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ GitHub Release: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ GitHub Release: {e}")
            return False
    
    def send_telegram_message(self, latest_data, csv_row_count: int) -> bool:
        """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡"""
        try:
            bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
            chat_id = os.getenv('TELEGRAM_CHAT_ID')
            
            if not bot_token or not chat_id:
                print("âš ï¸ TELEGRAM_BOT_TOKEN ÛŒØ§ TELEGRAM_CHAT_ID ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
                return False
            
            message = f"""Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØ§ {latest_data['date_pr']} - {latest_data['date_gr']}
ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ CSV: {csv_row_count:,}"""
            
            # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ
            url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
            data = {
                'chat_id': chat_id,
                'text': message
            }
            
            response = requests.post(url, data=data)
            if response.status_code != 200:
                print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {response.text}")
                return False
            
            # Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ CSV
            url_doc = f"https://api.telegram.org/bot{bot_token}/sendDocument"
            
            files_to_send = ['USD2Rials.csv', 'USD2Rials.json']
            
            for file_path in files_to_send:
                if os.path.exists(file_path):
                    with open(file_path, 'rb') as file:
                        files = {'document': file}
                        data = {'chat_id': chat_id}
                        response = requests.post(url_doc, data=data, files=files)
                        
                        if response.status_code == 200:
                            print(f"âœ… ÙØ§ÛŒÙ„ {file_path} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
                        else:
                            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„ {file_path}: {response.text}")
                else:
                    print(f"âš ï¸ ÙØ§ÛŒÙ„ {file_path} ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            return True
            
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {e}")
            return False
    
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø§ØµÙ„ÛŒ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ"""
        print("ğŸ”„ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù‚ÛŒÙ…Øª Ø¯Ù„Ø§Ø±...")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† Ù‚ÛŒÙ…Øª Ø§Ø² ÙˆØ¨Ø³Ø§ÛŒØª
        latest_data = self.fetch_latest_price()
        if not latest_data:
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² ÙˆØ¨Ø³Ø§ÛŒØª")
            return False
        
        print(f"ğŸ“Š Ù‚ÛŒÙ…Øª Ø¬Ø¯ÛŒØ¯ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {latest_data['date_pr']} - {latest_data['price_avg']:,} Ø±ÛŒØ§Ù„")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ø¢Ø®Ø±ÛŒÙ† Ø±Ø¯ÛŒÙ Ø§Ø² ÙØ§ÛŒÙ„
        last_entry = self.get_last_entry()
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨ÙˆØ¯Ù† Ø¯Ø§Ø¯Ù‡
        is_new_data = self.is_new_data(latest_data, last_entry)
        
        if is_new_data:
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ CSV
            if self.append_to_csv(latest_data):
                print("âœ… Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ ÙØ§ÛŒÙ„ CSV Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")
                
                # ØªÙˆÙ„ÛŒØ¯/Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ JSON Ù‡Ø§ Ùˆ Ø¯Ø±ÛŒØ§ÙØª ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§
                json_success, csv_row_count = self.regenerate_json_files()
                
                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ README Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§
                if self.update_readme(latest_data, last_entry, csv_row_count):
                    print("âœ… ÙØ§ÛŒÙ„ README Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯")
                else:
                    print("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ README")
                
                # Ø§ÛŒØ¬Ø§Ø¯ GitHub Release Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
                self.create_github_release(latest_data, csv_row_count)
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ² Ø§ÙˆÙ„ Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù…
                if self.is_first_day_of_persian_month(latest_data['date_pr']):
                    print("ğŸ“… Ø±ÙˆØ² Ø§ÙˆÙ„ Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ - Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…")
                    self.send_telegram_message(latest_data, csv_row_count)
                
                return True
            else:
                print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ ÙØ§ÛŒÙ„")
                return False
        else:
            print("â„¹ï¸ Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            # Ø­ØªÛŒ Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ Ù†Ø¨Ø§Ø´Ø¯ØŒ README Ùˆ JSONÙ‡Ø§ Ø±Ø§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©Ù†
            json_success, csv_row_count = self.regenerate_json_files()
            self.update_readme(latest_data, last_entry, csv_row_count)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ² Ø§ÙˆÙ„ Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… (Ø­ØªÛŒ Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ø¬Ø¯ÛŒØ¯ Ù†Ø¨Ø§Ø´Ø¯)
            if self.is_first_day_of_persian_month(latest_data['date_pr']):
                print("ğŸ“… Ø±ÙˆØ² Ø§ÙˆÙ„ Ù…Ø§Ù‡ Ø´Ù…Ø³ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯ - Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…")
                self.send_telegram_message(latest_data, csv_row_count)
            
            return True

if __name__ == "__main__":
    updater = USD2RialsUpdater()
    success = updater.run()
    exit(0 if success else 1)
